# Supabase CWE/CPE/CVE Data Extractor

> **Warning:** This tool is still in development. **Do not add this to production** yet!

---

## Overview

This tool is designed to extract and upload data related to CWE, CPE, and CVE into Supabase. It handles millions of records with efficient batching and relationship management between the datasets. Note that due to foreign key constraints, the CPE relationships might need special handling in your instance.

---

## Key Considerations

### Data Volume
- **CVE Data:**  
  - Adding CVE data to the nodes table could significantly increase the record count (by roughly 1M records).
  - This may slow down search operations because of the increased time complexity.

- **CPE Data:**  
  - The CPE table contains around 1M rows.
  - Adding detailed relationships (parent-child) can rapidly increase the complexity.
  - **Recommendation:** Only use the parent relationship. The detailed child relationships can be derived from the JSON data.

- **CWE Data:**  
  - Enriches the dataset with additional details (weaknesses, categories, etc.).
  - Requires new tables for a more comprehensive dataset.

### Data Relationships
- **CPE Relationships:**  
  - Represent parent-to-child relationships. For example, a "MacBook" (parent) might have child entries for different architectures (e.g., x86, ARM).
  - **Note:** It is highly recommended to avoid adding these child relationships explicitly. Instead, use the parent node and extract variations from the JSON data as needed.

### Future Improvements
1. **Concurrency:**  
   - Implement threading to process multiple batches simultaneously for increased speed.
   - This is not critical since the script runs at most once per day. If processing exceeds 10 minutes, recheck your setup or connection speed.

2. **Error Handling:**  
   - Currently, there is an error with unzipping the CPE files due to an invalid filename. The script continues to run despite this, so you may choose to ignore these errors.

---

## Script Breakdown

### Main Node Data Insert
This is the core component, responsible for:
- **Query Insertion:**  
  - Sequentially processes data from CPE, CVE, CWE and handles relationships using generated UUIDs from Supabase.
- **Query Data Script:**  
  - Inserts the data into Supabase and saves it locally for reference.
- **Files to Insert Data:**  
  - Manages the order in which files are ingested.

**Batching:**  
- Given that there are around 9 million rows from the CPE data alone, batching (e.g., 1000 records per batch) is implemented to avoid overwhelming your system.
- Uses `upsert()` to both avoid duplicates and update records, ensuring data integrity and freshness.

### Data Extraction
- **CPE, CVE, CWE Extraction:**  
  - Reads JSON files downloaded by the scraper.
  - Separates the extraction of relationships from the node logic (since relationships depend on UUIDs).
- **CWE Special Note:**  
  - Originally in XML format, hence requires different parsing and extraction logic.

### Scraper
- **Functionality:**  
  - Retrieves data from various sources hosting CWE, CPE, and CVE data.
  - Includes functions for batching and transforming CWE data from XML to JSON.
- **Batching:**  
  - The CPE files (around 1 GB each) are split into 2000+ smaller files for processing and uploading.

---

## Setup Instructions

1. **Environment Configuration:**
   - Update the `.env` file with your Supabase credentials.

2. **Database Setup:**
   - Manually create the required tables in your Supabase instance.
   - Use the provided `enum_sql_queries` for table creation.

3. **Running the Script:**
   - Execute the `main.js` file to start the data extraction and insertion process.

---

## Additional Notes

- **UUID Relationships:**  
  - Relationships depend on UUIDs generated by Supabase. Ensure sequential processing for these parts.
  
- **Error Handling:**  
  - Unzipping errors for CPE files due to invalid filenames are known issues. The script continues running despite these errors.

- **Future Enhancements:**  
  - Consider adding concurrency for faster batch processing.
  - Review and potentially refine error handling and logging for better troubleshooting.
